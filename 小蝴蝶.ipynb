{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = webdriver.Chrome()\n",
    "base = 'https://paela-iecosystem.meida.tw/'\n",
    "# url = 'https://paela-iecosystem.meida.tw/#/intimacy-4-2'\n",
    "\n",
    "Role = ['#/unintended-2']\n",
    "zh = ['我意外懷孕了']\n",
    "# 'youngdad-2'\n",
    "# 'daughter-2'\n",
    "string = []\n",
    "for k in Role:\n",
    "    url = base + k\n",
    "    web.get(url)\n",
    "    time.sleep(1)\n",
    "    page = web.page_source\n",
    "    Soup = BeautifulSoup(page,\"lxml\")\n",
    "    State1 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "    for i, j in enumerate(State1):\n",
    "        Options = State1[i]['href']\n",
    "        url = base + Options\n",
    "        web.get(url)\n",
    "        time.sleep(1)\n",
    "        page = web.page_source\n",
    "        Soup = BeautifulSoup(page,\"lxml\")\n",
    "        State2 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "        for m, n in enumerate(State2):\n",
    "            Options2 = State2[m]['href']\n",
    "            url = base + Options2\n",
    "            web.get(url)\n",
    "            time.sleep(1)\n",
    "            page = web.page_source\n",
    "            Soup = BeautifulSoup(page,\"lxml\")\n",
    "            State3 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "            for o, p in enumerate(State3):\n",
    "                str3 = '{\"Option3\":\"' + State3[o][\"href\"] + '\",\"Content\":\"' + State3[o].text + '\"}'\n",
    "                str2 = '{\"Option2\":\"' + State2[m][\"href\"] + '\",\"Content\":\"' + State2[m].text + '\",\"State3\":' + str3 + '}'\n",
    "                str1 = '{\"Option1\":\"' + State1[i][\"href\"] + '\",\"Content\":\"' + State1[i].text + '\",\"State2\":' + str2 + '}'\n",
    "                str0 = '{\"Role\":\"' + Role[0] + '\",\"Content\":\"' + zh[0] + '\",\"State\":' + str1 + '}'\n",
    "                string.append(str0)\n",
    "                # json_acceptable_string = str0.replace(\"'\", \"\\\"\")\n",
    "                # strf = json.loads(json_acceptable_string)\n",
    "                # string.append(strf)\n",
    "                \n",
    "                # string.append(Role[0] + ', ' + zh[0] + ', '   \n",
    "                #                 + State1[i]['href'] + ', ' + State1[i].text + ', '   \n",
    "                #                 + State2[m]['href'] + ', ' + State2[m].text + ', '   \n",
    "                #                 + State3[o]['href'] + ', ' + State3[o].text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(string).to_json(r'Options_test2.json', orient='split', force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.read_json(r'Options_test2.json' , orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "State2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "State3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "State2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r'小蝴蝶平台文案-總表 - 複製.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Content'] = ''\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = webdriver.Chrome()\n",
    "base = 'https://paela-iecosystem.meida.tw/#/'\n",
    "for i in range(len(data)):\n",
    "    url = base + data.iloc[i, 0]\n",
    "    web.get(url)\n",
    "    time.sleep(2)\n",
    "    page = web.page_source\n",
    "    \n",
    "\n",
    "    Soup = BeautifulSoup(page,\"lxml\")\n",
    "    # Content = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > div.select-menu > ul \")\n",
    "    # data.iloc[i, 1] = str(Content)\n",
    "\n",
    "    Content = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > div.select-menu > ul > li \")\n",
    "    data.iloc[i, 1] = str(Content)\n",
    "web.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(r'Content2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json(r'Content2.json',force_ascii=False, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import excel2json\n",
    "import pandas\n",
    "\n",
    "# excel_data_df = pandas.read_excel('Content2.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "json_str = data.to_json(orient='records',force_ascii=False)\n",
    "\n",
    "# print('Excel Sheet to JSON:\\n', json_str)\n",
    "# excel2json.convert_from_file('Content2.xlsx')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r'0321\\小蝴蝶尾頁頁碼_0321v2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = webdriver.Chrome()\n",
    "# base = 'https://paela-iecosystem.meida.tw/#/'\n",
    "base = 'http://localhost:8081/'\n",
    "for i in range(len(data)):\n",
    "    url = base + data.iloc[i, 0]\n",
    "    web.get(url)\n",
    "    time.sleep(2)\n",
    "    page = web.page_source\n",
    "    \n",
    "\n",
    "    Soup = BeautifulSoup(page,\"lxml\")\n",
    "    # Content = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > div.select-menu > ul \")\n",
    "    # data.iloc[i, 1] = str(Content)\n",
    "\n",
    "    Content = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > div.select-menu > ul > li \")\n",
    "    data.iloc[i, 1] = str(Content)\n",
    "web.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(r'0321\\小蝴蝶尾頁內容_0321v2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = webdriver.Chrome()\n",
    "base = 'https://paela-iecosystem.meida.tw/'\n",
    "# url = 'https://paela-iecosystem.meida.tw/#/intimacy-4-2'\n",
    "\n",
    "Role = ['#/unintended-2']\n",
    "zh = ['我意外懷孕了']\n",
    "# Option11 = ['#/intimacy-3-1']\n",
    "# Option22 = ['#/medical-3-1', '#/talking-4-1', '#/familyRelation-3-1', '#/intimacy-3-1']\n",
    "# 'unintended-2'\n",
    "# 'youngdad-2'\n",
    "# 'daughter-2'\n",
    "string = []\n",
    "for k in Role:\n",
    "    url = base + k\n",
    "    web.get(url)\n",
    "    time.sleep(1)\n",
    "    page = web.page_source\n",
    "    Soup = BeautifulSoup(page,\"lxml\")\n",
    "    State1 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "    for i, j in enumerate(State1):\n",
    "        Options = State1[i]['href']\n",
    "        url = base + Options\n",
    "        web.get(url)\n",
    "        time.sleep(1)\n",
    "        page = web.page_source\n",
    "        Soup = BeautifulSoup(page,\"lxml\")\n",
    "        State2 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "        for m, n in enumerate(State2):\n",
    "            Options2 = State2[m]['href']\n",
    "            url = base + Options2\n",
    "            web.get(url)\n",
    "            time.sleep(1)\n",
    "            page = web.page_source\n",
    "            Soup = BeautifulSoup(page,\"lxml\")\n",
    "            State3 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "            for o, p in enumerate(State3):\n",
    "                # 第一版\n",
    "                str0 = Role[0] + ',' + zh[0] + ',' + State1[i][\"href\"] + ',' + State1[i].text + ',' + State2[m][\"href\"] + ',' + State2[m].text + ',' + State3[o][\"href\"] + ',' + State3[o].text + ',' + State3[o]['href']\n",
    "                string.append(str0)\n",
    "\n",
    "                # 手刻\n",
    "                # str3 = '{\"Option3\":\"' + State3[o][\"href\"] + '\",\"Content\":\"' + State3[o].text + '\"}'\n",
    "                # str2 = '{\"Option2\":\"' + State2[m][\"href\"] + '\",\"Content\":\"' + State2[m].text + '\",\"State3\":' + str3 + '}'\n",
    "                # str1 = '{\"Option1\":\"' + State1[i][\"href\"] + '\",\"Content\":\"' + State1[i].text + '\",\"State2\":' + str2 + '}'\n",
    "                # str0 = '{\"Role\":\"' + Role[0] + '\",\"Content\":\"' + zh[0] + '\",\"State\":' + str1 + '}'\n",
    "                # dict1 = str0\n",
    "\n",
    "                # json_acceptable_string = str0.replace(\"'\", \"\\\"\")\n",
    "                # strf = json.loads(json_acceptable_string)\n",
    "                # string.append(strf)\n",
    "                \n",
    "                # string.append(Role[0] + ', ' + zh[0] + ', '   \n",
    "                #                 + State1[i]['href'] + ', ' + State1[i].text + ', '   \n",
    "                #                 + State2[m]['href'] + ', ' + State2[m].text + ', '   \n",
    "                #                 + State3[o]['href'] + ', ' + State3[o].text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame(string)\n",
    "A[['Role', 'zh', 'Option1', 'Content1', 'Option2', 'Content2', 'Option3', 'Content3', 'href']] = A[0].str.split(\",\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = A.copy()\n",
    "B.drop(columns=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdrec(df):\n",
    "    drec = dict()\n",
    "    ncols = df.values.shape[1]\n",
    "    for line in df.values:\n",
    "        d = drec\n",
    "        for j, col in enumerate(line[:-1]):\n",
    "            if not col in d.keys():\n",
    "                if j != ncols-2:\n",
    "                    d[col] = {}\n",
    "                    d = d[col]\n",
    "                else:\n",
    "                    d[col] = line[-1]\n",
    "            else:\n",
    "                if j!= ncols-2:\n",
    "                    d = d[col]\n",
    "    return drec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nested_json = pd.DataFrame(string)\n",
    "Nested_json[['Role', 'zh', 'Option1', 'Content1', 'Option2', 'Content2', 'Option3', 'Content3', 'href']] = Nested_json[0].str.split(\",\", expand=True)\n",
    "Nested_json.drop(columns=0, inplace=True)\n",
    "Nested = fdrec(Nested_json[['zh','Content1', 'Content2', 'Content3' ,'href']])\n",
    "# pd.DataFrame(Nested).to_json('for_api3.json',force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手刻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = webdriver.Chrome()\n",
    "base = 'https://paela-iecosystem.meida.tw/'\n",
    "# url = 'https://paela-iecosystem.meida.tw/#/intimacy-4-2'\n",
    "\n",
    "Role = ['#/unintended-2']\n",
    "# , '#/youngdad-2', '#/daughter-2']\n",
    "zh = ['我意外懷孕了']\n",
    "# , '我女友懷孕了', '我女兒懷孕了']\n",
    "# Option11 = ['#/intimacy-3-1']\n",
    "# Option22 = ['#/medical-3-1', '#/talking-4-1', '#/familyRelation-3-1', '#/intimacy-3-1']\n",
    "# 'unintended-2'\n",
    "# 'youngdad-2'\n",
    "# 'daughter-2'\n",
    "string = []\n",
    "for l, k in enumerate(Role) :\n",
    "    url = base + k\n",
    "    web.get(url)\n",
    "    time.sleep(1)\n",
    "    page = web.page_source\n",
    "    Soup = BeautifulSoup(page,\"lxml\")\n",
    "    State1 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "    for i, j in enumerate(State1):\n",
    "        Options = State1[i]['href']\n",
    "        url = base + Options\n",
    "        web.get(url)\n",
    "        time.sleep(1)\n",
    "        page = web.page_source\n",
    "        Soup = BeautifulSoup(page,\"lxml\")\n",
    "        State2 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "        # State21 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div > div > div:nth-child(2) > ul > li\")\n",
    "        for m, n in enumerate(State2):\n",
    "            Options2 = State2[m]['href']\n",
    "            url = base + Options2\n",
    "            web.get(url)\n",
    "            time.sleep(1)\n",
    "            page = web.page_source\n",
    "            Soup = BeautifulSoup(page,\"lxml\")\n",
    "            State3 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "            State31 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div > div > ul > li\")\n",
    "            if State3 != []:\n",
    "                for o, p in enumerate(State3):\n",
    "                    # 第一版\n",
    "                    str0 = Role[l] + ',' + zh[l] + ',' + State1[i][\"href\"] + ',' + State1[i].text + ',' + State2[m][\"href\"] + ',' + State2[m].text + ',' + \\\n",
    "                                                        State3[o][\"href\"] + ',' + State3[o].text + ',' + State31[o].text \n",
    "                    string.append(str0)\n",
    "            else:\n",
    "                for q, r in enumerate(State3):\n",
    "                    Options3 = State3[q]['href']\n",
    "                    url = base + Options3\n",
    "                    web.get(url)\n",
    "                    time.sleep(1)\n",
    "                    page = web.page_source\n",
    "                    Soup = BeautifulSoup(page,\"lxml\")\n",
    "                    State4 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "                    State41 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div > div > div:nth-child(2) > ul > li\")\n",
    "                    for s, t in enumerate(State4):\n",
    "                        str0 = Role[l] + ',' + zh[l] + ',' + State1[i][\"href\"] + ',' + State1[i].text + ',' + State2[m][\"href\"] + ',' + State2[m].text + ',' + \\\n",
    "                                                            State3[o][\"href\"] + ',' + State3[o].text + ',' + State31[o].text + ',' + State4[s][\"href\"] + ',' + State4[s].text + ',' + State41[s].text  \n",
    "                        string.append(str0)\n",
    "                # 手刻  \n",
    "                # dict3 = {\"Option3\": State3[o][\"href\"], \"Content\": State3[o].text }\n",
    "                # dict2 = {\"Option2\": State2[m][\"href\"], \"Content\": State2[m].text, \"State3\":dict3 }\n",
    "                # dict1 = {\"Option1\": State1[i][\"href\"], \"Content\": State1[i].text, \"State2\":dict2 }\n",
    "                # dict0 = {\"Role\":Role[0], \"Content\": zh[0], \"State\":dict1}\n",
    "                # string.append(dict0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(string).to_json(r'第三版.json', force_ascii=False, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame(string)\n",
    "A[['Role', 'zh', 'Option1', 'Content1', 'Option2', 'Content2', 'Option3', 'Content3', 'href']] = A[0].str.split(\",\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = webdriver.Chrome()\n",
    "base = 'https://paela-iecosystem.meida.tw/'\n",
    "# url = 'https://paela-iecosystem.meida.tw/#/intimacy-4-2'\n",
    "\n",
    "Role = ['#/unintended-2', '#/youngdad-2', '#/daughter-2']\n",
    "zh = ['我意外懷孕了', '我女友懷孕了', '我女兒懷孕了']\n",
    "# Option11 = ['#/intimacy-3-1']\n",
    "# Option22 = ['#/medical-3-1', '#/talking-4-1', '#/familyRelation-3-1', '#/intimacy-3-1']\n",
    "# 'unintended-2'\n",
    "# 'youngdad-2'\n",
    "# 'daughter-2'\n",
    "string = []\n",
    "for l, k in enumerate(Role) :\n",
    "    url = base + k\n",
    "    web.get(url)\n",
    "    time.sleep(1)\n",
    "    page = web.page_source\n",
    "    Soup = BeautifulSoup(page,\"lxml\")\n",
    "    State1 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "    for i, j in enumerate(State1):\n",
    "        Options = State1[i]['href']\n",
    "        url = base + Options\n",
    "        web.get(url)\n",
    "        time.sleep(1)\n",
    "        page = web.page_source\n",
    "        Soup = BeautifulSoup(page,\"lxml\")\n",
    "        State2 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "        for m, n in enumerate(State2):\n",
    "            Options2 = State2[m]['href']\n",
    "            url = base + Options2\n",
    "            web.get(url)\n",
    "            time.sleep(1)\n",
    "            page = web.page_source\n",
    "            Soup = BeautifulSoup(page,\"lxml\")\n",
    "            State3 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "            State31 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div > div > ul > li\")\n",
    "            if State3 != []:\n",
    "                for o, p in enumerate(State3):\n",
    "                    # 第一版\n",
    "                    str0 = Role[l] + ',' + zh[l] + ',' + State1[i][\"href\"] + ',' + State1[i].text + ',' + \\\n",
    "                        State2[m][\"href\"] + ',' + State2[m].text + ',' + \\\n",
    "                        State3[o][\"href\"] + ',' + State3[o].text + ',' + State31[o].text \n",
    "                    string.append(str0)\n",
    "            else:\n",
    "                for q, r in enumerate(State3):\n",
    "                    Options3 = State3[q]['href']\n",
    "                    url = base + Options3\n",
    "                    web.get(url)\n",
    "                    time.sleep(1)\n",
    "                    page = web.page_source\n",
    "                    Soup = BeautifulSoup(page,\"lxml\")\n",
    "                    State4 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "                    State41 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div > div > div:nth-child(2) > ul > li\")\n",
    "                    for s, t in enumerate(State4):\n",
    "                        str0 = Role[l] + ',' + zh[l] + ',' + State1[i][\"href\"] + ',' + State1[i].text + ',' + \\\n",
    "                            State2[m][\"href\"] + ',' + State2[m].text + ',' + \\\n",
    "                            State3[o][\"href\"] + ',' + State3[o].text + ',' + State31[o].text + ',' + \\\n",
    "                            State4[s][\"href\"] + ',' + State4[s].text + ',' + State41[s].text  \n",
    "                        string.append(str0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame(string)\n",
    "A[['Role', 'zh', 'Option1', 'Content1', 'Option2', 'Content2', 'Option3', 'Content3', 'sContent3']] = A[0].str.split(\",\", expand=True)\n",
    "A.drop(columns=0, inplace=True)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.Role = A.Role.str.replace('#/', '')\n",
    "A.Option1 = A.Option1.str.replace('#/', '')\n",
    "A.Option2 = A.Option2.str.replace('#/', '')\n",
    "A.Option3 = A.Option3.str.replace('#/', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([A.groupby('Role')\\\n",
    "  .apply(lambda x: x.groupby('Option1')\\\n",
    "                    .apply(lambda x: [x.groupby('Option2')\n",
    "                                       .apply(lambda x: x[['Option3','Content3', 'sContent3']].to_dict('r')\n",
    "                                              ).to_dict()]\n",
    "                          ).to_dict()\n",
    "  ).to_dict()]).to_json(r'Test1.json', force_ascii=False, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "State1[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "State1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = webdriver.Chrome()\n",
    "base = 'https://paela-iecosystem.meida.tw/'\n",
    "# url = 'https://paela-iecosystem.meida.tw/#/intimacy-4-2'\n",
    "\n",
    "Role = ['#/unintended-2', '#/youngdad-2', '#/daughter-2']\n",
    "zh = ['我意外懷孕了', '我女友懷孕了', '我女兒懷孕了']\n",
    "# Option11 = ['#/intimacy-3-1']\n",
    "# Option22 = ['#/medical-3-1', '#/talking-4-1', '#/familyRelation-3-1', '#/intimacy-3-1']\n",
    "# 'unintended-2'\n",
    "# 'youngdad-2'\n",
    "# 'daughter-2'\n",
    "string = []\n",
    "for l, k in enumerate(Role) :\n",
    "    url = base + k\n",
    "    web.get(url)\n",
    "    time.sleep(1)\n",
    "    page = web.page_source\n",
    "    Soup = BeautifulSoup(page,\"lxml\")\n",
    "    State1 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "    for i, j in enumerate(State1):\n",
    "        Options = State1[i]['href']\n",
    "        url = base + Options\n",
    "        web.get(url)\n",
    "        time.sleep(1)\n",
    "        page = web.page_source\n",
    "        Soup = BeautifulSoup(page,\"lxml\")\n",
    "        State2 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "        for m, n in enumerate(State2):\n",
    "            Options2 = State2[m]['href']\n",
    "            url = base + Options2\n",
    "            web.get(url)\n",
    "            time.sleep(1)\n",
    "            page = web.page_source\n",
    "            Soup = BeautifulSoup(page,\"lxml\")\n",
    "            State3 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "            State31 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div > div > ul > li\")\n",
    "            if State3 != []:\n",
    "                for o, p in enumerate(State3):\n",
    "                    # 第一版\n",
    "                    str0 = Role[l] + ',' + zh[l] + ',' + State1[i][\"href\"] + ',' + State1[i].text + ',' + \\\n",
    "                        State2[m][\"href\"] + ',' + State2[m].text + ',' + \\\n",
    "                        State3[o][\"href\"] + ',' + State3[o].text + ',' + State31[o].text \n",
    "                    string.append(str0)\n",
    "            else:\n",
    "                for q, r in enumerate(State3):\n",
    "                    Options3 = State3[q]['href']\n",
    "                    url = base + Options3\n",
    "                    web.get(url)\n",
    "                    time.sleep(1)\n",
    "                    page = web.page_source\n",
    "                    Soup = BeautifulSoup(page,\"lxml\")\n",
    "                    State4 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div.container.step-box > div > ul > li > a\")\n",
    "                    State41 = Soup.select(\"#\\#app > div > div:nth-child(2) > div:nth-child(7) > main > section.container.step-rwd > div > div > div > div:nth-child(2) > ul > li\")\n",
    "                    for s, t in enumerate(State4):\n",
    "                        str0 = Role[l] + ',' + zh[l] + ',' + State1[i][\"href\"] + ',' + State1[i].text + ',' + \\\n",
    "                            State2[m][\"href\"] + ',' + State2[m].text + ',' + \\\n",
    "                            State3[o][\"href\"] + ',' + State3[o].text + ',' + State31[o].text + ',' + \\\n",
    "                            State4[s][\"href\"] + ',' + State4[s].text + ',' + State41[s].text  \n",
    "                        string.append(str0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame(string)\n",
    "A[['Role', 'zh', 'Option1', 'Content1', 'Option2', 'Content2', 'Option3', 'Content3', 'sContent3']] = A[0].str.split(\",\", expand=True)\n",
    "A.drop(columns=0, inplace=True)\n",
    "A.Role = A.Role.str.replace('#/', '')\n",
    "A.Option1 = A.Option1.str.replace('#/', '')\n",
    "A.Option2 = A.Option2.str.replace('#/', '')\n",
    "A.Option3 = A.Option3.str.replace('#/', '')\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_Table = pd.DataFrame()\n",
    "ID_Table = pd.concat([ID_Table, A['Role']], axis=0)\n",
    "ID_Table = pd.concat([ID_Table, A['Option1']], axis=0)\n",
    "ID_Table = pd.concat([ID_Table, A['Option2']], axis=0)\n",
    "ID_Table = pd.concat([ID_Table, A['Option3']], axis=0)\n",
    "ID_Table = ID_Table.drop_duplicates()\n",
    "ID_Table.reset_index(drop=True, inplace=True)\n",
    "ID_Table.reset_index(inplace=True)\n",
    "ID_Table.rename(columns={0:'ID_key', 'index':'ID'}, inplace=True)\n",
    "ID_Table.to_excel(r'ID_Table.xlsx', index=False)\n",
    "ID_Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table1 = A[['Role', 'zh']].drop_duplicates()\n",
    "Table1['ID_key'] = A['Role']\n",
    "Table1 = pd.merge(Table1, ID_Table, how='left', on=['ID_key'])\n",
    "Table1.drop(columns='ID_key', inplace=True)\n",
    "Table1.rename(columns={'Role':'address', 'zh':'title'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table2 = A[['Role', 'Option1', 'Content1']].drop_duplicates()\n",
    "Table2['ID_key'] = A['Option1']\n",
    "Table2 = pd.merge(Table2, ID_Table, how='left', on=['ID_key'])\n",
    "Table2.drop(columns='ID_key', inplace=True)\n",
    "Table2.rename(columns={'Option1':'address', 'Content1':'title'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table3 = A[['Option1', 'Option2', 'Content2']].drop_duplicates()\n",
    "Table3['ID_key'] = A['Option2']\n",
    "Table3 = pd.merge(Table3, ID_Table, how='left', on=['ID_key'])\n",
    "Table3.drop(columns='ID_key', inplace=True)\n",
    "Table3.rename(columns={'Option2':'address', 'Content2':'title'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第四層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table4 = A[['Option2', 'Option3', 'Content3', 'sContent3']].drop_duplicates()\n",
    "Table4['ID_key'] = A['Option3']\n",
    "Table4 = pd.merge(Table4, ID_Table, how='left', on=['ID_key'])\n",
    "Table4.drop(columns='ID_key', inplace=True)\n",
    "Table4.rename(columns={'Option3':'address', 'Content3':'title', 'sContent3':'content'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('文案表格.xlsx',engine='xlsxwriter')   \n",
    "# Table1.to_excel(writer,sheet_name='Table1', index=False)   \n",
    "# Table2.to_excel(writer,sheet_name='Table2', index=False)   \n",
    "# Table3.to_excel(writer,sheet_name='Table3', index=False)   \n",
    "# Table4.to_excel(writer,sheet_name='Table4', index=False)   \n",
    "# writer.save()\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = Table1.groupby('address').apply(lambda x:x[['ID', 'address', 'title']].to_dict('r')).to_dict()\n",
    "T2 = Table2.groupby('Role').apply(lambda x:x[['ID', 'address', 'title']].to_dict('r')).to_dict()\n",
    "T3 = Table3.groupby('Option1').apply(lambda x:x[['ID', 'address', 'title']].to_dict('r')).to_dict()\n",
    "T4 = Table4.groupby('Option2').apply(lambda x:x[['ID', 'address', 'title', 'content']].to_dict('r')).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in T3:\n",
    "    for k in T3[i]:\n",
    "        if k['address'] in T4:\n",
    "            k['Option3'] = T4[k['address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in T2:\n",
    "    for k in T2[i]:\n",
    "        if k['address'] in T3:\n",
    "            k['Option2'] = T3[k['address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in T1:\n",
    "    for k in T1[i]:\n",
    "        if k['address'] in T2:\n",
    "            k['Option1'] = T2[k['address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(T1).to_json(r'小蝴蝶測試.json', force_ascii=False, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIX ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = webdriver.Chrome()\n",
    "# base = 'https://paela-iecosystem.meida.tw/'\n",
    "base = 'http://localhost:8081/'\n",
    "# url = 'https://paela-iecosystem.meida.tw/#/intimacy-4-2'\n",
    "\n",
    "Role = ['#/unintended-2', '#/youngdad-2', '#/daughter-2', '#/support-2']\n",
    "# ]\n",
    "zh = ['我意外懷孕了', '我女友懷孕了', '我女兒懷孕了', '我想支持']\n",
    "# ]我意外懷孕了\n",
    "\n",
    "string = []\n",
    "# 角色\n",
    "for i, j in enumerate(Role) :\n",
    "    url = base + j\n",
    "    web.get(url)\n",
    "    time.sleep(1)\n",
    "    page = web.page_source\n",
    "    Soup = BeautifulSoup(page,\"lxml\")\n",
    "    State1 = Soup.select(\"ul.step-menu > li.aos-init:not(.d-none) > a\")\n",
    "    State11 = Soup.select(\"ul.step-menu > li.aos-init:not(.d-none) > p\")\n",
    "    # 第一層\n",
    "    for k, l in enumerate(State1):\n",
    "        Option1 = State1[k]['href']\n",
    "        url = base + Option1\n",
    "        web.get(url)\n",
    "        time.sleep(1)\n",
    "        page = web.page_source\n",
    "        Soup = BeautifulSoup(page,\"lxml\")\n",
    "        State2 = Soup.select(\"ul.step-menu > li.aos-init:not(.d-none) > a\")\n",
    "        State22 = Soup.select(\"ul.step-menu > li.aos-init:not(.d-none) > p\")\n",
    "        # 第二層\n",
    "        for m, n in enumerate(State2):\n",
    "            Option2 = State2[m]['href']\n",
    "            url = base + Option2\n",
    "            web.get(url)\n",
    "            time.sleep(1)\n",
    "            page = web.page_source\n",
    "            Soup = BeautifulSoup(page,\"lxml\")\n",
    "            State3 = Soup.select(\"ul.step-menu > li.aos-init:not(.d-none) > a\")\n",
    "            State33 = Soup.select(\"ul.step-menu > li.aos-init:not(.d-none) > p\")\n",
    "            if State3 == []:\n",
    "                str0 = Role[i] + ',' + zh[i] + ',' +  \\\n",
    "                        State1[k]['href'] + ',' + State1[k].text + ',' + State11[k].text + ',' + \\\n",
    "                        State2[m]['href'] + ',' + State2[m].text + ',' + State22[m].text + ', , , , , , , , , '\n",
    "                string.append(str0)\n",
    "            else:\n",
    "                # 第三層\n",
    "                for o, p in enumerate(State3):\n",
    "                    Option3 = State3[o]['href']\n",
    "                    url = base + Option3\n",
    "                    web.get(url)\n",
    "                    time.sleep(1)\n",
    "                    page = web.page_source\n",
    "                    Soup = BeautifulSoup(page,\"lxml\")\n",
    "                    State4 = Soup.select(\"ul.step-menu > li.aos-init:not(.d-none) > a\")\n",
    "                    State44 = Soup.select(\"ul.step-menu > li.aos-init:not(.d-none) > p\")\n",
    "                    if State4 == []:\n",
    "                        str0 = Role[i] + ',' + zh[i] + ',' +  \\\n",
    "                                State1[k]['href'] + ',' + State1[k].text + ',' + State11[k].text + ',' + \\\n",
    "                                State2[m]['href'] + ',' + State2[m].text + ',' + State22[m].text + ',' + \\\n",
    "                                State3[o]['href'] + ',' + State3[o].text + ',' + State33[o].text + ', , , , , , '\n",
    "                        string.append(str0)\n",
    "                    else:\n",
    "                        # 第四層\n",
    "                        for s, t in enumerate(State4):\n",
    "                            Option4 = State4[s]['href']\n",
    "                            url = base + Option4\n",
    "                            web.get(url)\n",
    "                            time.sleep(1)\n",
    "                            page = web.page_source\n",
    "                            Soup = BeautifulSoup(page,\"lxml\")\n",
    "                            State5 = Soup.select(\"ul.step-menu > li.aos-init:not(.d-none) > a\")\n",
    "                            State55 = Soup.select(\"ul.step-menu > li.aos-init:not(.d-none) > p\")\n",
    "                            if State5 == []:\n",
    "                                str0 = Role[i] + ',' + zh[i] + ',' +  \\\n",
    "                                    State1[k]['href'] + ',' + State1[k].text + ',' + State11[k].text + ',' + \\\n",
    "                                    State2[m]['href'] + ',' + State2[m].text + ',' + State22[m].text + ',' + \\\n",
    "                                    State3[o]['href'] + ',' + State3[o].text + ',' + State33[o].text + ',' + \\\n",
    "                                    State4[s]['href'] + ',' + State4[s].text + ',' + State44[s].text +', , , '\n",
    "                                string.append(str0)\n",
    "                            else:\n",
    "                                for r, q in enumerate(State5):\n",
    "                                    str0 = Role[i] + ',' + zh[i] + ',' +  \\\n",
    "                                        State1[k]['href'] + ',' + State1[k].text + ',' + State11[k].text + ',' + \\\n",
    "                                        State2[m]['href'] + ',' + State2[m].text + ',' + State22[m].text + ',' + \\\n",
    "                                        State3[o]['href'] + ',' + State3[o].text + ',' + State33[o].text + ',' + \\\n",
    "                                        State4[s]['href'] + ',' + State4[s].text + ',' + State44[s].text + ',' + \\\n",
    "                                        State5[r]['href'] + ',' + State5[r].text + ',' + State55[r].text\n",
    "                                    string.append(str0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame(string)\n",
    "A[['Role', 'zh', \n",
    "    'Option1', 'Title1', 'Content1' ,\n",
    "    'Option2', 'Title2', 'Content2' ,\n",
    "    'Option3', 'Title3', 'Content3' ,\n",
    "    'Option4', 'Title4', 'Content4' ,\n",
    "    'Option5', 'Title5', 'Content5']] = A[0].str.split(\",\", expand=True)\n",
    "A.drop(columns=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"\" href=\"#/familyRelation-4-7\">父母不同意墮胎</a>,\n",
       " <a class=\"\" href=\"#/familyRelation-4-3\">如何跟爸媽說懷孕了</a>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.to_excel(r'小蝴蝶頁碼test.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21028b07f43f8532f9b2183370e542e6ccc7383657941d49f9b7b9d87c4222d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
